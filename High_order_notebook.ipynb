{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIGH ORDER NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors : GIRIER Guillaume, DESROCHES Mathieu, RODRIGUES Serafim (Basque Center for Applied Mathematics)**\n",
    "\n",
    "**Contact : guillaumegirier@gmail.com**\n",
    "\n",
    "**Objective :**\n",
    "\n",
    "*The purpose of this notebook is to guide the user through the different functions of this project, as well as to provide some examples to understand how it works.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cmath\n",
    "\n",
    "from scipy.stats import norm\n",
    "from itertools import combinations\n",
    "from scipy.special import digamma\n",
    "\n",
    "import dit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions :**\n",
    "\n",
    "**gaussian_ent_biascorr()** *compute the bias corrector for the entropy estimator based on covariance matrix of gaussian.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_ent_biascorr(N,T):\n",
    "\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tINPUTS:\n",
    "\t\n",
    "\tN = Number of dimensions\n",
    "\tT = Sample size\n",
    "\t\n",
    "\tOUTPUTS\n",
    "\t\n",
    "\tbiascorr = bias corrector value\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tvalues = np.arange(1, N+1)\n",
    "\t\n",
    "\treturn 0.5 * ((N * np.log(2/(T-1))) + np.sum(list(map(lambda n : digamma((T-n)/2), values))) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*example :*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias corrector for the entropy :  -0.11306231630611352\n"
     ]
    }
   ],
   "source": [
    "N = 2\n",
    "T = 15\n",
    "print(\"Bias corrector for the entropy : \", gaussian_ent_biascorr(N,T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data2gaussian()** *transforms 'data' to Gaussian with mean = 0 and sd = 1 using empirical copulas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2gaussian (data) :\n",
    "\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tINPUTS :\n",
    "\t\n",
    "\tdata = T samples x N variables matrix\n",
    "\t\n",
    "\tOUTPUTS :\n",
    "\t\n",
    "\tgaussian_data = T samples x N variables matrix with the gaussian copula transformed data.\n",
    "\tcovmat = N x N covariance matrix of gaussian copula transformed data.\n",
    "\t\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tT = len(data)\n",
    "\tsort_index = np.argsort(data, axis = 0) # Sort the data and keep the indexes.\n",
    "\tcopdata = np.argsort(sort_index, axis = 0) # Sorting sorting indexes\n",
    "\tcopdata += 1 # To avoid 0 because of the python indexation\n",
    "\tcopdata = copdata/ (T+1) # Normalization.\n",
    "\tgaussian_data = norm.ppf(copdata, 0, 1) # PPF : Probability Density Function  => Gaussian data\n",
    "\tgaussian_data[~np.isfinite(gaussian_data)] = 0 # Removing -Inf\n",
    "\tcov_mat = np.dot(np.transpose(gaussian_data), gaussian_data ) / (T-1) # Covariance matrix\n",
    "\t\n",
    "\treturn gaussian_data, cov_mat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*example :*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "gaussian data : \n",
      " [[-0.4307273  0.4307273]\n",
      " [ 0.4307273 -0.4307273]] \n",
      "\n",
      "Covariance matrix :\n",
      " [[ 0.37105201 -0.37105201]\n",
      " [-0.37105201  0.37105201]]\n"
     ]
    }
   ],
   "source": [
    "real_data = np.array([[ 2., 4.], [ 5., 1.]])\n",
    "\n",
    "gaussian_data, cov_mat = data2gaussian(real_data)\n",
    "\n",
    "\n",
    "test = np.array([[ 0., 0.], [ 1, 0]])\n",
    "\n",
    "d = dit.Distribution.from_ndarray(test)\n",
    "print(dit.multivariate.total_correlation(d))\n",
    "\n",
    "print(\"gaussian data : \\n\", gaussian_data, \"\\n\")\n",
    "print(\"Covariance matrix :\\n\",cov_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ent_fun()** *and* **reduce_x()** *are two functions used in soinfo_from_covmat().*\n",
    "\n",
    "**ent_fun()** *function compute the entropy of multivariate gaussian distribution where x is dimensionality and y is the variables variance of the covariance matrix determinant.*\n",
    "\n",
    "**reduce_x()** *remove the line and row x in order to obtain a submatrix len(covmat)-1x len(covmat)-1.*\n",
    "\n",
    "**soinfo_from_covmat()** *computes the 0-information and S-information of gaussian data given their covariance matrix 'covmat'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ent_fun (x,y):\n",
    "\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tIn order to avoid log(0), we replace the returned value as NaN value.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tif (( 2*np.pi*np.exp(1) ) ** x) * y == 0:\n",
    "\t\n",
    "\t\treturn np.nan\n",
    "\telse:\n",
    "\t\treturn 0.5 * cmath.log((( 2*np.pi*np.exp(1) ) ** x) * y)\n",
    "\n",
    "\n",
    "\n",
    "def reduce_x (x, covmat):\n",
    "\n",
    "\tcovmat = np.delete(covmat, x, axis = 0)\n",
    "\tcovmat = np.delete(covmat, x, axis = 1)\n",
    "\t\n",
    "\treturn covmat\n",
    "\n",
    "\n",
    "\n",
    "def soinfo_from_covmat (covmat, T):\n",
    "\t\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tINPUTS :\n",
    "\t\n",
    "\tcovmat = N x N covariance matrix\n",
    "\tT = lenght data\n",
    "\t\n",
    "\tOUPUTS :\n",
    "\t\n",
    "\toinfo = O - Information\n",
    "\tsinfo = S - Information of the system with covariance matrix 'covmat'.\n",
    "\t\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tcovmat = np.array(covmat)\n",
    "\tN = len(covmat)\n",
    "\temp_det = np.linalg.det(covmat) # Determinant\n",
    "\tsingle_vars = np.diag(covmat) # Variance of single variables (Diagonal matrix values)\n",
    "\t\n",
    "\t### Bias corrector for N, (N-1) and one gaussian variables :\n",
    "\t\n",
    "\tbiascorrN = gaussian_ent_biascorr(N, T)\n",
    "\tbiascorrNmin1 = gaussian_ent_biascorr(N-1, T)\n",
    "\tbiascorr_1 = gaussian_ent_biascorr(1, T)\n",
    "\t\n",
    "\t### Computing estimated measures for multi-variate gaussian variables :\n",
    "\t\n",
    "\ttc = np.sum(list(map(lambda x : ent_fun(1,x), single_vars)) - biascorr_1) - (ent_fun(N,emp_det) - biascorrN) #Total correlation\n",
    "\t\n",
    "\tHred = 0\n",
    "\t\n",
    "\tfor red in range(1, N+1):\n",
    "\t\tHred += ent_fun((N-1), np.linalg.det(reduce_x(red-1, covmat))) - biascorrNmin1\n",
    "\t\t\n",
    "\tdtc = Hred - (N-1) * (ent_fun(N, emp_det)-biascorrN) # dtc = Dual Total Correlation\n",
    "\n",
    "\toinfo = tc - dtc\n",
    "\tsinfo = tc + dtc\n",
    "\t\n",
    "\treturn oinfo, sinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*example :*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sinfo =  0j\n",
      "Oinfo =  (0.6132741758614122-3.141592653589793j)\n"
     ]
    }
   ],
   "source": [
    "covmat = [[ 1., 2.], [ 3., 4.]]\n",
    "T = 15\n",
    "\n",
    "\n",
    "sinfo, oinfo = soinfo_from_covmat (covmat, T)\n",
    "print('Sinfo = ', sinfo)\n",
    "print('Oinfo = ', oinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**high_order()** *compute S-Information, O-Information, and characterize the High Order interactions among n variables governed by Redundancy or Synergy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_order (data, n):\n",
    "\n",
    "\t\"\"\" \n",
    "\t\n",
    "\tINPUTS :\n",
    "\t\n",
    "\tdata = Matrix with dimensionality (N,T), where N is the number of brain regions or \n",
    "\tmodules, and T is the number of samples.\n",
    "\tn = number of interactions or n-plets.\n",
    "\t\n",
    "\tOUTPUTS :\n",
    "\tRed = Matrix with dimension (1, Modules), with the redundancy values per patient \n",
    "\tand per module.\n",
    "\tSyn = Matrix with dimension (1, Modules), with synergy values per patient \n",
    "\tand per module.\n",
    "\tOinfo = O-Information for all the n-plets.\n",
    "\tSinfo = S-Information for all the n-plets.\n",
    "\t\n",
    "\t\"\"\"\n",
    "\n",
    "\t### INITIALISATION :\n",
    "\t\n",
    "\tModules = len(data)\n",
    "\tRed = np.zeros(Modules) \n",
    "\tSyn = np.zeros(Modules)\n",
    "\t\n",
    "\tvector = np.arange(0, Modules)\n",
    "\tnplets = []\n",
    "\t\n",
    "\t\t\n",
    "\tOinfo = []\n",
    "\tSinfo = []\n",
    "\t\n",
    "\t\n",
    "\t### N-PLETS CALCULATION :\n",
    "\t\n",
    "\tfor x in combinations(vector, n): # n-tuples without repetition over 20 modules\n",
    "\t\tnplets.append(x)\n",
    "\tnplets = np.array(nplets)\n",
    "\n",
    "\t### DATA NORMALISATION :\n",
    "\n",
    "\tmean = np.mean(data, axis = 1)\n",
    "\tmean = mean.reshape(-1,1)\n",
    "\t\n",
    "\tdataNorm = data - mean\n",
    "\n",
    "\tgaussian_data, cov_mat = data2gaussian (np.transpose(dataNorm)) # Transformation to Copulas and Covariance Matrix Estimation\n",
    "\t\n",
    "\ti = 0\n",
    "\t\n",
    "\t### OINFO AND SINFO COMPUTATION :\t\n",
    "\n",
    "\tInfo = []\n",
    "\tInfo.append(list(map(lambda x : soinfo_from_covmat(cov_mat[np.ix_(x,x)], len(dataNorm[0])), nplets)))\n",
    "\tInfo = np.transpose(Info)\n",
    "\tOinfo = np.array(Info[0])\n",
    "\tSinfo = np.array(Info[1])\n",
    "\t\n",
    "\t### REDUNDANCY AND SYNERGY COMPUTATION :\n",
    "\t\n",
    "\t\"\"\"\n",
    "\tHere, we want to verify in each nplet if a module exist : when it is the case we compute\n",
    "\tthe associated Redundancy and Synergy, according to the Oinfo value of these nplets.\n",
    "\t\"\"\"\n",
    "\tValues = []\n",
    "\t\n",
    "\tfor module in range(Modules):\n",
    "\t\tValues, cols = np.where(nplets == module)\n",
    "\t\t\n",
    "\t\tOinfo_module_pos = []\n",
    "\t\tOinfo_module_neg = []\n",
    "\t\t\n",
    "\t\tfor i in range(len(Values)):\n",
    "\n",
    "\t\t\tif Oinfo[Values[i]].real > 0 :\n",
    "\t\t\t\tOinfo_module_pos.append(Oinfo[Values[i]].real)\n",
    "\t\t\tif Oinfo[Values[i]].real < 0 :\n",
    "\t\t\t\tOinfo_module_neg.append(Oinfo[Values[i]].real)\n",
    "\n",
    "\t\tRed[module] = np.mean(np.array(Oinfo_module_pos))\n",
    "\t\tSyn[module] = np.mean(np.absolute(np.array(Oinfo_module_neg)))\n",
    "\t\t\n",
    "\t\tValues = []\n",
    "\t\t\n",
    "\tRed = Red.reshape(-1,1)\n",
    "\tSyn = Syn.reshape(-1,1)\n",
    "\t\n",
    "\tnp.nan_to_num(Syn)\n",
    "\t\t\n",
    "\t\n",
    "\treturn Red, Syn, Oinfo, Sinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*example 1 : Toy example*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment :\n",
      "Data shape :  (5, 10)\n",
      "N-plet : N =  3\n",
      "Red = \n",
      " [[0.0093925 ]\n",
      " [0.00595465]\n",
      " [0.01136318]\n",
      " [0.01257646]\n",
      " [0.01121641]]\n",
      "Syn = \n",
      " [[0.04521023]\n",
      " [0.0792501 ]\n",
      " [0.04348603]\n",
      " [0.04607233]\n",
      " [0.02819029]]\n",
      "Oinfo = \n",
      " [[ 0.0036509 +0.j]\n",
      " [-0.0792501 +0.j]\n",
      " [ 0.0063793 +0.j]\n",
      " [ 0.0181473 +0.j]\n",
      " [-0.04348603+0.j]\n",
      " [-0.01289456+0.j]\n",
      " [ 0.00331553+0.j]\n",
      " [ 0.00964334+0.j]\n",
      " [ 0.00678416+0.j]\n",
      " [ 0.02205885+0.j]]\n",
      "Sinfo = \n",
      " [[-0.11421223+0.j]\n",
      " [ 0.2619684 +0.j]\n",
      " [-0.14121204+0.j]\n",
      " [-0.28507303+0.j]\n",
      " [ 0.01545767+0.j]\n",
      " [-0.17268191+0.j]\n",
      " [-0.18133203+0.j]\n",
      " [-0.31477674+0.j]\n",
      " [-0.15281791+0.j]\n",
      " [-0.24202692+0.j]]\n"
     ]
    }
   ],
   "source": [
    "fil = 'data.txt'\n",
    "data = np.loadtxt(fil)\n",
    "data = np.transpose(data)\n",
    "\n",
    "n = 3\n",
    "\n",
    "print(\"Experiment :\")\n",
    "print(\"Data shape : \", np.shape(data))\n",
    "print(\"N-plet : N = \", n)\n",
    "Red, Syn, Oinfo, Sinfo = high_order (data, n)\n",
    "\n",
    "\n",
    "print(\"Red = \\n\", Red)\n",
    "print(\"Syn = \\n\", Syn)\n",
    "print(\"Oinfo = \\n\", Oinfo)\n",
    "print(\"Sinfo = \\n\", Sinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*example 2 : EEG Data example*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment :\n",
      "Data shape :  (20, 150)\n",
      "N-plet : N =  3\n",
      "Red = \n",
      " [[0.1016804 ]\n",
      " [0.16686132]\n",
      " [0.1702303 ]\n",
      " [0.14864651]\n",
      " [0.17163629]\n",
      " [0.16153031]\n",
      " [0.13749736]\n",
      " [0.08065497]\n",
      " [0.03668144]\n",
      " [0.15752672]\n",
      " [0.1597381 ]\n",
      " [0.15708144]\n",
      " [0.14333413]\n",
      " [0.09416274]\n",
      " [0.07987271]\n",
      " [0.10106591]\n",
      " [0.05822325]\n",
      " [0.11747604]\n",
      " [0.15068438]\n",
      " [0.1589152 ]]\n",
      "Syn = \n",
      " [[0.01118193]\n",
      " [0.0269671 ]\n",
      " [0.01564277]\n",
      " [0.0110644 ]\n",
      " [0.01695087]\n",
      " [0.01054038]\n",
      " [0.00997889]\n",
      " [0.00273669]\n",
      " [0.01180196]\n",
      " [0.00985562]\n",
      " [0.0100757 ]\n",
      " [0.00396579]\n",
      " [0.01014993]\n",
      " [0.00688864]\n",
      " [0.00449911]\n",
      " [0.01339305]\n",
      " [0.00977817]\n",
      " [0.01140549]\n",
      " [0.00491404]\n",
      " [0.01086349]]\n",
      "Oinfo = \n",
      " [[ 0.25357335+0.j]\n",
      " [ 0.19106312+0.j]\n",
      " [ 0.24604218+0.j]\n",
      " ...\n",
      " [-0.01663759+0.j]\n",
      " [ 0.03658603+0.j]\n",
      " [ 0.22221867+0.j]]\n",
      "Sinfo = \n",
      " [[1.44442979+0.j]\n",
      " [1.36255458+0.j]\n",
      " [1.45602463+0.j]\n",
      " ...\n",
      " [0.69480616+0.j]\n",
      " [0.99432633+0.j]\n",
      " [1.359193  +0.j]]\n"
     ]
    }
   ],
   "source": [
    "fil = 'sub-01_task-seegstim_run-01_epochs.npy'\n",
    "data = np.load(fil)\n",
    "\n",
    "\n",
    "n_epoch=data.shape[0] # Number of epochs\n",
    "n_signal=data.shape[1] # Number of signals\n",
    "n_point=data.shape[2] # Number voltage values at each epoch\n",
    "\n",
    "# Extract the signals\n",
    "# signals: (256,38*2081) matrix\n",
    "signals=np.zeros((n_signal,n_epoch*n_point))\n",
    "for i in range (n_signal):\n",
    "    for j in range (n_epoch):\n",
    "        signals[i,j*n_point:(j+1)*n_point]=data[j,i,:]\n",
    "\n",
    "data = np.zeros((20, 150))\n",
    "\n",
    "for i in range(len(data)):\n",
    "\tfor j in range(len(data[i])):\n",
    "\t\tdata[i][j] = signals[i][j]\n",
    "\n",
    "n = 3\n",
    "\n",
    "print(\"Experiment :\")\n",
    "print(\"Data shape : \", np.shape(data))\n",
    "print(\"N-plet : N = \", n)\n",
    "Red, Syn, Oinfo, Sinfo = high_order (data, n)\n",
    "\n",
    "\n",
    "print(\"Red = \\n\", Red)\n",
    "print(\"Syn = \\n\", Syn)\n",
    "print(\"Oinfo = \\n\", Oinfo)\n",
    "print(\"Sinfo = \\n\", Sinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
